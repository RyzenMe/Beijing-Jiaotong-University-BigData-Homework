{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks with Sci-kit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Gist of Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network is a supervised classification algorithm. With your help, it kind of teaches itself how to make better classifications.\n",
    "\n",
    "For a basic neural net, you have three primary components: an input layer, a hidden layer, and an output layer, each consisting of nodes. The nodes of the input layer are basically your input variables; the nodes of the hidden layer are neurons that contain some function that operates on your input data; and there is one output node, which uses a function on the values given by the hidden layer, and then there is a final output given by this calculation. If this isn't making much sense yet, don't worry. \n",
    "\n",
    "Each node is connected to every other node in the layers in front of it, so in other words, your input nodes aren't connected to each other, but they will be connected to every node in the hidden layer, and every node in the hidden layer will be connected to the output node.\n",
    "\n",
    "![basic neural net](http://www.texample.net/media/tikz/examples/PNG/neural-network.png)\n",
    "\n",
    "The gray lines connecting input nodes to neurons (nodes in the hidden layer) are all weighted. These weights are some value between 0 and 1, and will be multiplied with whatever the input value is. Any node in the hidden layer — let's say $Node_A$ — will essentially have two functions; a combination function and an activation function. The combination function will likely take the summation of all of the input nodes times their respective weights. Where W is weight and X is input:\n",
    "\n",
    "**Summation function: **\n",
    "\n",
    "$Net_A = \\sum W_{iA}X_{iA} = W_{0A}(1) + W_{1A}X_{1A} + W_{2A}X_{2A} + W_{3A}X_{3A}$\n",
    "\n",
    "This is basically saying that for the first node in the hidden layer (which we've called $Node_A$), every connection to it will be summed up. So the first input and its weight is denoted $W_{1A}X_{1A}$. The second input that connects to $Node_A$ and its weight is denoted $W_{2A}X_{2A}$, and so forth. The first term $W_{0A}$ will always be constant ```1```, where this term is a constant factor, much like the intercept in regression models.\n",
    "\n",
    "If we make up some inputs and weights, the equation will look something like this:\n",
    "\n",
    "$ Net_A = (1)(0.5) + (0.4)(0.6) + (0.2)(0.8) + (0.7)(0.6) = 1.32$\n",
    "\n",
    "The resulting ```1.32``` would then be input into the activation function (likely sigmoid).\n",
    "\n",
    "**Sigmoid function: **\n",
    "\n",
    "$y = \\frac{1}{1 + e^{-x}}$\n",
    "\n",
    "$y = \\frac{1}{1 + e^{-1.32}} = 0.7892$\n",
    "\n",
    "This value is then given to the output node, $Node_Z$. $Node_Z$ then combines these outputs from Nodes A, B, etc. into a weighted sum (using the weights associated with the connections of these nodes). Now, $X_i$ is treated as the outputs from each node in the hidden layer, and the formula from above is used again.\n",
    "\n",
    "$Net_Z = \\sum W_{iZ} = W_{0Z} + W_{AZ}X_{AZ} + W_{BZ}X_{BZ}$\n",
    "\n",
    "The sigmoid is used again on the output of $Net_Z$, producing the true output value of the neural network's first run. Then it's run again and again for however many data points have been defined.\n",
    "\n",
    "The weights are what make and break the accuracy of the entire neural network. When the NN is initialized, these weights will be randomized. The neural net then operates and creates its output value, and this value is matched against what it *should* be. The error is taken, and then the neural net uses some user-defined method to go back through the net to adjust the weights so that the accuracy is maximized, and the error is minimized.\n",
    "\n",
    "I don't really expect anybody to fully grasp what is happening from these simple descriptions. At the bottom of the notebook, I will link some other resources that are useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tabulate\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier #you will probably need to update sklearn/conda\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.notebook_repr_html', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Clem3Training.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>demogweight</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  demogweight  education  education-num  \\\n",
       "0   39         State-gov        77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc        83311  Bachelors             13   \n",
       "2   38           Private       215646    HS-grad              9   \n",
       "3   53           Private       234721       11th              7   \n",
       "4   28           Private       338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country  income  \n",
       "0          2174             0              40  United-States  <=50K.  \n",
       "1             0             0              13  United-States  <=50K.  \n",
       "2             0             0              40  United-States  <=50K.  \n",
       "3             0             0              40  United-States  <=50K.  \n",
       "4             0             0              40           Cuba  <=50K.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gov' 'Self' 'Private' '?' 'Without-pay' 'Never-worked']\n",
      "['n' 'y']\n",
      "['White' 'Black' 'Asian-Pac-Islander' 'Amer-Indian-Eskimo' 'Other']\n",
      "White                 21391\n",
      "Black                  2379\n",
      "Asian-Pac-Islander      775\n",
      "Amer-Indian-Eskimo      241\n",
      "Other                   214\n",
      "Name: race, dtype: int64\n",
      "n    13215\n",
      "y    11785\n",
      "Name: marital-status-cats, dtype: int64\n",
      "Private         17385\n",
      "Gov              3367\n",
      "Self             2835\n",
      "?                1399\n",
      "Without-pay         9\n",
      "Never-worked        5\n",
      "Name: workclass-cats, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Creates two columns that will be used as their categorical counterparts\n",
    "df['marital-status-cats'] = df['marital-status'].copy()\n",
    "df['workclass-cats'] = df['workclass'].copy()\n",
    "\n",
    "#This dictionary is interpreted as; in column of df, the key will be replaced by the value\n",
    "category_replacement = {'marital-status-cats' : {'Married-civ-spouse': 'y', 'Married-AF-spouse': 'y', 'Married-spouse-absent': 'y',\n",
    "                                                'Divorced': 'n', 'Widowed': 'n', 'Separated': 'n', 'Never-married': 'n'},\n",
    "                        'workclass-cats': {'Federal-gov': 'Gov', 'Local-gov': 'Gov', 'State-gov': 'Gov', 'Self-emp-inc': 'Self',\n",
    "                                           'Self-emp-not-inc': 'Self'}}\n",
    "#Reduces the number of categories\n",
    "df.replace(category_replacement, inplace=True)\n",
    "\n",
    "print(df['workclass-cats'].unique())\n",
    "print(df['marital-status-cats'].unique())\n",
    "print(df['race'].unique())\n",
    "\n",
    "print(df.race.value_counts())\n",
    "print(df['marital-status-cats'].value_counts())\n",
    "print(df['workclass-cats'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding for Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical classes: ['<=50K.' '>50K.']\n",
      "Integer classes: [0 1]\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "\n",
    "##CODE BLOCK FOR VARIABLE ENCODINGS##\n",
    "\n",
    "#####################################\n",
    "\n",
    "#Encoding Income\n",
    "enc = LabelEncoder()\n",
    "\n",
    "label_encoder = enc.fit(df['income'])\n",
    "print (\"Categorical classes:\", label_encoder.classes_)\n",
    "\n",
    "integer_classes = label_encoder.transform(label_encoder.classes_)\n",
    "print (\"Integer classes:\", integer_classes)\n",
    "\n",
    "\n",
    "#Encoding Marital-Status\n",
    "label_encoder = enc.fit(df['marital-status-cats'])\n",
    "integer_classes = label_encoder.transform(label_encoder.classes_)\n",
    "df['marital-encoded'] = label_encoder.transform(df['marital-status-cats'])\n",
    "\n",
    "#Encoding race\n",
    "label_encoder = enc.fit(df['race'])\n",
    "integer_classes = label_encoder.transform(label_encoder.classes_)\n",
    "df['race-encoded'] = label_encoder.transform(df['race'])\n",
    "\n",
    "#Encoding sex\n",
    "label_encoder = enc.fit(df['sex'])\n",
    "integer_classes = label_encoder.transform(label_encoder.classes_)\n",
    "df['sex-encoded'] = label_encoder.transform(df['sex'])\n",
    "\n",
    "#Encoding workclass\n",
    "label_encoder = enc.fit(df['workclass-cats'])\n",
    "integer_classes = label_encoder.transform(label_encoder.classes_)\n",
    "df['workclass-encoded'] = label_encoder.transform(df['workclass-cats'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I should perhaps use OneHotEncoder on some of these variables that have more than two unique values. When there is a range [0,4], categories that are far from each other could be misunderstood by our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Standardization for Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "\n",
    "##CODE BLOCK FOR MIN-MAX TRANSFORMATIONS##\n",
    "\n",
    "##########################################\n",
    "\n",
    "#Standardizing age so numeric values aren't misrepresented in calculations\n",
    "df['age_mm'] = (df['age'] - (df['age'].min()) / (df['age'].max() - df['age'].min()))\n",
    "\n",
    "df['education-num_mm'] = (df['education-num'] - (df['education-num'].min()) / (df['education-num'].max() - df['education-num'].min()))\n",
    "df['capital-gain_mm'] = (df['capital-gain'] - (df['capital-gain'].min()) / (df['capital-gain'].max() - df['capital-gain'].min()))\n",
    "df['capital-loss_mm'] = (df['capital-loss'] - (df['capital-loss'].min()) / (df['capital-loss'].max() - df['capital-loss'].min()))\n",
    "df['hours-per-week_mm'] = (df['hours-per-week'] - (df['hours-per-week'].min()) / (df['hours-per-week'].max() - df['hours-per-week'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>demogweight</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>...</th>\n",
       "      <th>workclass-cats</th>\n",
       "      <th>marital-encoded</th>\n",
       "      <th>race-encoded</th>\n",
       "      <th>sex-encoded</th>\n",
       "      <th>workclass-encoded</th>\n",
       "      <th>age_mm</th>\n",
       "      <th>education-num_mm</th>\n",
       "      <th>capital-gain_mm</th>\n",
       "      <th>capital-loss_mm</th>\n",
       "      <th>hours-per-week_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>Gov</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.767123</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.989796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>Self</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>49.767123</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.989796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>Private</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>37.767123</td>\n",
       "      <td>8.933333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.989796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>Private</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>52.767123</td>\n",
       "      <td>6.933333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.989796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>Private</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27.767123</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.989796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  demogweight  education  education-num  \\\n",
       "0   39         State-gov        77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc        83311  Bachelors             13   \n",
       "2   38           Private       215646    HS-grad              9   \n",
       "3   53           Private       234721       11th              7   \n",
       "4   28           Private       338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "         ...          workclass-cats  marital-encoded  race-encoded  \\\n",
       "0        ...                     Gov                0             4   \n",
       "1        ...                    Self                1             4   \n",
       "2        ...                 Private                0             4   \n",
       "3        ...                 Private                1             2   \n",
       "4        ...                 Private                1             2   \n",
       "\n",
       "  sex-encoded workclass-encoded     age_mm education-num_mm  capital-gain_mm  \\\n",
       "0           1                 1  38.767123        12.933333           2174.0   \n",
       "1           1                 4  49.767123        12.933333              0.0   \n",
       "2           1                 3  37.767123         8.933333              0.0   \n",
       "3           1                 3  52.767123         6.933333              0.0   \n",
       "4           0                 3  27.767123        12.933333              0.0   \n",
       "\n",
       "   capital-loss_mm  hours-per-week_mm  \n",
       "0              0.0          39.989796  \n",
       "1              0.0          12.989796  \n",
       "2              0.0          39.989796  \n",
       "3              0.0          39.989796  \n",
       "4              0.0          39.989796  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>race-encoded</th>\n",
       "      <th>sex-encoded</th>\n",
       "      <th>capital-gain_mm</th>\n",
       "      <th>capital-loss_mm</th>\n",
       "      <th>education-num_mm</th>\n",
       "      <th>age_mm</th>\n",
       "      <th>hours-per-week_mm</th>\n",
       "      <th>marital-encoded</th>\n",
       "      <th>workclass-encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>38.767123</td>\n",
       "      <td>39.989796</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>49.767123</td>\n",
       "      <td>12.989796</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.933333</td>\n",
       "      <td>37.767123</td>\n",
       "      <td>39.989796</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.933333</td>\n",
       "      <td>52.767123</td>\n",
       "      <td>39.989796</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>27.767123</td>\n",
       "      <td>39.989796</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   income  race-encoded  sex-encoded  capital-gain_mm  capital-loss_mm  \\\n",
       "0  <=50K.             4            1           2174.0              0.0   \n",
       "1  <=50K.             4            1              0.0              0.0   \n",
       "2  <=50K.             4            1              0.0              0.0   \n",
       "3  <=50K.             2            1              0.0              0.0   \n",
       "4  <=50K.             2            0              0.0              0.0   \n",
       "\n",
       "   education-num_mm     age_mm  hours-per-week_mm  marital-encoded  \\\n",
       "0         12.933333  38.767123          39.989796                0   \n",
       "1         12.933333  49.767123          12.989796                1   \n",
       "2          8.933333  37.767123          39.989796                0   \n",
       "3          6.933333  52.767123          39.989796                1   \n",
       "4         12.933333  27.767123          39.989796                1   \n",
       "\n",
       "   workclass-encoded  \n",
       "0                  1  \n",
       "1                  4  \n",
       "2                  3  \n",
       "3                  3  \n",
       "4                  3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#A little bit of dataframe tidying\n",
    "\n",
    "#Dropping unnecessary columns\n",
    "to_drop = ['age', 'hours-per-week', 'capital-loss', 'capital-gain', 'education-num', 'demogweight', 'education', 'relationship', 'native-country', 'marital-status', 'marital-status-cats', 'workclass-cats', 'workclass', 'occupation', 'sex', 'race']\n",
    "df = df.drop(to_drop, axis = 1)\n",
    "\n",
    "#Reordering the columns to make it easier to use model_selection function\n",
    "cols = ['income', 'race-encoded', 'sex-encoded', 'capital-gain_mm', 'capital-loss_mm', 'education-num_mm', 'age_mm','hours-per-week_mm', 'marital-encoded', 'workclass-encoded']\n",
    "df = df[cols]\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning the Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_x = df.iloc[:,1:] #All of the input variables, from race-ended onward\n",
    "df_y = df.iloc[:, 0] #The target variable, income\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size = .2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data must be partitioned into training and test sets because neural networks are a supervised learning method. You have to feed the model pre-classified data (the training set), and then its classifications are judged on how well they predict the test data. The ```train_test_split``` function makes this super convenient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 656 ms\n",
      "Neural net accuracy: 0.781\n"
     ]
    }
   ],
   "source": [
    "nn = MLPClassifier(activation = 'logistic', solver = 'sgd', hidden_layer_sizes = (7,), max_iter = 2000, random_state = 3)\n",
    "%time nn.fit(x_train, y_train)\n",
    "print(\"Neural net accuracy: \" + str(nn.score(x_test, y_test, sample_weight=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ```random_state``` ensures that there is some consistency in sampling every time you run the neural net (which is useful because I'm giving multiple examples here). \n",
    "\n",
    "2. ```max_iter``` being set to 2000 ensures that I can run neural nets with many hidden layers, each with many neurons, otherwise my examples below might cause an iteration error. \n",
    "\n",
    "3. Logistic ```activation``` is saying that the NN uses a sigmoid activation function. \n",
    "\n",
    "4. ```solver``` determines how the algorithm is going to go through the neural net to adjust the weights (for the sake of minimizing error and increasing accuracy), and for this exercise I've used 'sgd' or 'stochastic gradient descent' because it's a quicker method than the standard gradient descent. The standard descent goes through every data item, while its stochastic counterpart uses a random sample.\n",
    "\n",
    "5. ```hidden_layer_sizes``` is a beast deserving of its own section.\n",
    "\n",
    "  * **Number of hidden layers:** Looking at hidden_layer_size in the table below, you may see one number, e.g. the first column is (5, ). Some of the values hold two numbers (5, 5), or more. If you see one number, that means there is one hidden layer. So (5, ) represents a single hidden layer, while (5, 5) represents two hidden layers, and so forth. \n",
    "\n",
    "  * **Number of neurons in the hidden layer:** The actual number that you're seeing (like 5) is how many neurons sit within that hidden layer. In the table below, in the first column, there are 5 neurons in the hidden layer. In the second column, there are 5 neurons in the first hidden layer, and 5 neurons in the second hidden layer. Go to the last column, there are 100 neurons in the first hidden layer, 100 in the second hidden layer, and 100 in the third hidden layer. Though I've used consistent numbers throughout each hidden layer, you could just as well have variations, like (15, 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>hidden_layer_size     </td><td>(5, ) </td><td>(5, 5)</td><td>(15, 15)</td><td>(20, 20)</td><td>(100, 100)</td><td>(20, 20, 20, 20)</td><td>(60, 60, 60, 60)</td><td>(100, 100, 100)</td></tr>\n",
       "<tr><td>Processing time       </td><td>1.12 s</td><td>5.39 s</td><td>2.92 s  </td><td>3.95 s  </td><td>29.8 s    </td><td>458 ms          </td><td>710 ms          </td><td>18.4 s         </td></tr>\n",
       "<tr><td>Accuracy of neural net</td><td>0.763 </td><td>0.763 </td><td>0.7788  </td><td>0.7788  </td><td>0.8106    </td><td>0.763           </td><td>0.763           </td><td>0.7788         </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = [[\"hidden_layer_size\", \"(5, )\", \"(5, 5)\", \"(15, 15)\", \"(20, 20)\", \"(100, 100)\", \"(20, 20, 20, 20)\", \"(60, 60, 60, 60)\", \"(100, 100, 100)\"],\n",
    "         [\"Processing time\", \"1.12 s\", \"5.39 s\", \"2.92 s\", \"3.95 s\", \"29.8 s\", \"458 ms\", \"710 ms\", \"18.4 s\"],\n",
    "         [\"Accuracy of neural net\", 0.7630, 0.7630, 0.7788, 0.7788, 0.8106, 0.7630, 0.763, 0.7788]]\n",
    "         \n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Optimum Number of Layers and Nodes\n",
    "\n",
    "Looking to the table above, you see some peculiarities:\n",
    "\n",
    "1. (5, 5) takes longer to compute than (20, 20) and even (60, 60, 60, 60)\n",
    "2. Accuracy dramatically drops when going from (100, 100) to (100, 100, 100)\n",
    "\n",
    "There are more, but the second interestingly points us to some important rules when determining the number of layers and nodes to use in the model. Increasing the number of hidden layers beyond 2 is arbitrary and decreases the power of back propagation (the algorithm that helps neural networks shine, by going backwards and altering input weights for increased accuracy). As for speed, I'm not quite sure why that happens, but a guess would be that when you have more hidden layers, the libraries do better in utilizing more CPU cores than less. If you use other libraries like Tensorflow, you can opt to use the GPU to run the network instead.\n",
    "\n",
    "[jj\\_](https://stats.stackexchange.com/a/180052/163011) from StackExchange shares Jeff Heaton's criteria for choosing how many neurons to use:\n",
    "\n",
    "**How many hidden nodes/neurons should I use?**\n",
    "\n",
    "\n",
    ">The number of hidden neurons should be between the size of the input layer and the size of the output layer.\n",
    "\n",
    ">The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer.\n",
    "\n",
    ">The number of hidden neurons should be less than twice the size of the input layer.\n",
    "\n",
    "\n",
    "We can calculate these easily—visually, even, by looking at our dataframe header and counting the input variables. From 'race-encoded' to 'workclass-encoded', we have 9 input nodes. Neural nets always have one output node. Using the second criterion, (9) * (2 / 3) + 1 = 7. All of the listed criteria are fulfilled.\n",
    "\n",
    "Shown above, using one hidden layer and 7 neurons in that layer, we get an accuracy of 0.781. It might be tempting to hack at the neural net to try to get a higher accuracy, but you would be lying to yourself. It isn't healthy to have the neural net learn the training dataset *too* completely, because then you have a neural net that is really close to the heart of your dataset, but can't be generalized to new data. This is known as **overfitting.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources:\n",
    "\n",
    "[Sklearn Documentation](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) MLPClassifier is one of Sklearn's neural network models, in which MLP stands for multi-layer perceptron.\n",
    "\n",
    "[Understanding Neural Networks with Tensorflow Playground](https://cloud.google.com/blog/big-data/2016/07/understanding-neural-networks-with-tensorflow-playground) This is an awesome resource for gaining an intuition about how neural nets work. You can play with their model, adding and subtracting hidden layers and neurons, to see how the data's dimensions are reduced, and how its values are transformed in space. Visualizing what the sigmoid function is actually doing is super helpful.\n",
    "\n",
    "[Visualizing Representations](https://colah.github.io/posts/2015-01-Visualizing-Representations/) This set of visualizations is linked in the previous resource but in case anyone glosses over it, it's also helpful in that there are real-world examples regarding language and textual data."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
